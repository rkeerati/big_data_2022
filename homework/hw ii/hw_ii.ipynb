{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data in Finance: Part III <BR><BR>Homework 2: Momentum Factor\n",
    "    \n",
    "**Instructor** <BR>\n",
    "Ritt Keerati, ritt.keerati@gsb.columbia.edu\n",
    "    \n",
    "**TA's:** <BR>\n",
    "Meha Sadasivam, MSadasivam21@gsb.columbia.edu <BR>\n",
    "Daheng Yang, dyang22@gsb.columbia.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due:** Thursday, April 1 at 11:59pm. Late submission will *not* be accepted. \n",
    "\n",
    "**Goal:** Last class we went through the building blocks to create investable portfolios from characteristics that forecast future returns. In this homework you are going to explore a different characteristic that has traditionally been associated with future returns: the past performance. The momemtum strategy is the one that invests in a portfolio that goes long stock with high past performance (high past returns) and short the ones with low performance (low past returns). Your goal in this homework is to calculate the cumulative returns of the momentum portolio from 1970.\n",
    "\n",
    "**Since we will cover the momentum factor in more details in our last lecture, for this assignment you will focus your efforts on portfolio sort (Part 4) and comparing your results to those from Fama and French (Part 5).**\n",
    "\n",
    "**Delivery:** Upload on canvas a .zip file with your code (it might include .ipynb or .py) and your answers (.html notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "For this homework you need the fire_pytools package that you can find in the Bitbucket repository [here](https://bitbucket.org/liramota/fire_pytools/). \n",
    "\n",
    "fire_pytools stands for (FI)nance (RE)search python tools and contains a bunch of useful functions, including data download, portfolio sorts, etc.\n",
    "\n",
    "You should save the fire_pytools in folder in your computer and adapt the code below with the path for the package.\n",
    "\n",
    "If you decide to download the fire_pytools to separate folder and you are using PyCharm, the best way to use an external library in pycharm is by adding the library PATH to your project. Check [here](https://www.jetbrains.com/help/pycharm/configuring-content-roots.html) if you have problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# Packages \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import time\n",
    "from time import strptime, strftime\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Setups\n",
    "pd.set_option(\"display.max_rows\", 100) # max number or rows to be displayed \n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages from fire_pytools\n",
    "sys.path.append(\"/Users/rk2941/Dropbox/courses/big_data_2022/fire_pytools\")\n",
    "\n",
    "# Data Import\n",
    "from data_setup import stock_monthly\n",
    "from data_setup import stock_annual\n",
    "\n",
    "# Functions \n",
    "from utils.monthly_date import *\n",
    "from portools.find_breakpoints import find_breakpoints\n",
    "from portools.sort_portfolios import sort_portfolios\n",
    "from import_kf.kf_factors import *\n",
    "from utils.post_event_nan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same data we used in class. It use data download from CRSP\n",
    "#mdata = stock_monthly.main()\n",
    "#mdata.to_pickle(path = '/Users/rk2941/Dropbox/courses/big_data_2022/data/stock_monthly.pkl')\n",
    "mdata = pd.read_pickle('/Users/rk2941/Dropbox/courses/big_data_2022/data/stock_monthly.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate past 11-1 returns\n",
    "\n",
    "In order to calculate the momentum factor, first we need to calculate the \"past cumulative returns\". This is the only characteristic that you need to construct yourself. But the code is already here for you.\n",
    "\n",
    "The original Carhart (1997) paper offers many windows of cumulating returns and months to be skipped before the formation date. In the code we have adopted the notation ret_{window}_{skip}, where {window} is the number of months to cumulate the returns and {skip} is the number of months to be skipped before this return is used for sorting.\n",
    "\n",
    "ð‘Ÿð‘’ð‘¡\\_11\\_1  is the 11 months cumulative returns, skipping 1 month, or, it is cumulative returns from 12 months before to one month before the formation date. This is the characteristic we are going to use to calculate the MOM factor.\n",
    "\n",
    "Be careful, the ret_{window}_{skip} notation is not to be confused with the Ken French notation. Since we are going to hold it for the following month, when Ken French report returns, he calls them: \"portfolios formed on prior (2-12) return\". Again, this for portfolio holding returns, not sorts.\n",
    "\n",
    "Make sure to be mindful about missing returns. We are going to follow the convention in Daniel and Moskowitz, JFE 2016, that says: \"We require that a firm ... [has] a minimum of eight monthly returns over the past 11 months, skipping the most recent month\". That means that if there are less than eight valid returns in the 11-period, we should set ret_11_1 equal to missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "## Data start in 2010\n",
    "mdata = mdata[mdata.date>='2010-01-01']\n",
    "## Share type - select only common stocks \n",
    "mdata = mdata[mdata.shrcd.isin([10, 11])]\n",
    "## Select stocks traded on the major stock exchanges\n",
    "mdata = mdata[mdata.exchcd.isin([1, 2, 3])]\n",
    "## Set index\n",
    "mdata.set_index(['permno','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate excess returns\n",
    "mdata['exret'] = mdata['retadj'] - mdata['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate past returns \n",
    "def calculate_cumulative_returns(mdata, tt, min_periods):\n",
    "    \"\"\"\n",
    "    Calculate past returns for momentum stratagy\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    mdata: data frame\n",
    "        crsp monthly data with cols permno, date as index.\n",
    "    tt: int\n",
    "        number of periods to cumulate retuns\n",
    "    min_periods: int\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    required_cols = ['retadj']\n",
    "\n",
    "    assert set(required_cols).issubset(mdata.columns), \"Required columns: {}.\".format(', '.join(required_cols))\n",
    "\n",
    "    df = mdata[required_cols].copy()\n",
    "\n",
    "    # Before applying the function calculate_cumulative_returns you need to make sure \n",
    "    # we don't have missing dates. Missing dates would lead to the wrong number of periods \n",
    "    # to cumulate returns.\n",
    "\n",
    "    # Resample data \n",
    "    # CRSP data has skipping months.\n",
    "    # Create line to missing  months to facilitate the calculation of lag/past returns\n",
    "    df.reset_index(inplace=True)\n",
    "    df['edate'] = df['date'] + MonthEnd(0)\n",
    "    df.sort_values(['permno', 'edate'], inplace=True)\n",
    "    pk_integrity(df, ['permno', 'edate'])\n",
    "    df.set_index(['edate'], inplace=True)\n",
    "    # Resample to take care of missing months\n",
    "    sdf = df[['permno', 'retadj']].groupby('permno').resample('M').mean().drop(columns='permno')\n",
    "    sdf.reset_index(inplace=True)\n",
    "    print(\"Time to resample data: %s seconds\" % str(time.time() - start_time))\n",
    "    print(\"We have added %s rows to the data\" % str(sdf.shape[0] - df.shape[0]))\n",
    "\n",
    "    # Cumulative Return (adjusted) in tt months\n",
    "    sdf['gret'] = sdf['retadj'].fillna(0)+1\n",
    "    sdf['ret_notnull'] = sdf['retadj'].notnull()\n",
    "\n",
    "    cret = sdf.groupby(['permno']).gret.rolling(window=tt, min_periods=1).apply(np.prod, raw=True)\n",
    "    cret.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    nona_count = sdf.groupby(['permno']).ret_notnull.rolling(window=tt, min_periods=1).apply(np.sum, raw=True)\n",
    "    nona_count.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cret[nona_count<min_periods] = np.nan\n",
    "    sdf['ret' + str(tt)] = cret\n",
    "\n",
    "    # Delete rows that were not in the original data set\n",
    "    df.reset_index(inplace=True)\n",
    "    fdata = pd.merge(df,\n",
    "             sdf[['edate', 'permno','ret' + str(tt)]],\n",
    "             on = ['edate', 'permno'])         \n",
    "    fdata.set_index(['permno','date'],inplace = True)\n",
    "    x = fdata['ret' + str(tt)]\n",
    "\n",
    "    print(\"Time to calculate %d months past returns: %s seconds\" % (tt, str(round(time.time() - start_time, 2))))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to resample data: 39.52799415588379 seconds\n",
      "We have added 1909 rows to the data\n",
      "Time to calculate 11 months past returns: 49.07 seconds\n"
     ]
    }
   ],
   "source": [
    "## Calculate 11 months returns\n",
    "mdata['ret11'] = calculate_cumulative_returns(mdata, 11, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mdata.ret11.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skip one month \n",
    "mdata['ret11_1'] = mdata.groupby(['permno']).ret11.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MEsum: when sorting by size this is the ME to be used\n",
    "mdata['mesum'] = mdata.groupby(['date', 'permco']).me.transform(np.sum, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolios Sorts\n",
    "\n",
    "Your task in this question is to do portfolio sorting. Use the function \"sort_portfolios\" to sort stocks into portfolio buckets.\n",
    "\n",
    "Check [Ken French's website](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) for Mom factor description. \n",
    "\n",
    "Every end of month, sort stocks into 2 X 3 buckets according to ME and ret_11_1. We follow Ken French website, and use 50th percentile for ME and 30th and 70th percentiles  for ret_11_1.\n",
    "\n",
    "Calculate the ME value weighted returns for each of the 6 portfolios sorted. Make sure that, for every month, you use information that is available for investors at the time of portfolio formation. Plot the cumulative returns for each of them.\n",
    "\n",
    "Calculate the MOM returns. From Ken French website: Mom is the average return on the two high prior return portfolios minus the average return on the two low prior return portfolios,\n",
    "\n",
    "$$Mom =\t\\frac{1}{2}(Small High + Big High) - \\frac{1}{2}(Small Low + Big Low).$$\t \n",
    "\n",
    "Plot the cumulative returns and report the average returns, standard devation and Sharpe-Ratio. Is your MOM portfolio returns similar to the one published in the Ken French website? Report the correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Fama and French\n",
    "Download Ken French's **Momentum Factor (Mom)** from [Ken French's website](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html). Compare your momentum factor to the data from Fama and French. Report the correlation between the two series, and plot the two series on the same chart for comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
